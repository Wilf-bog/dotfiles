
<p>Seit Monaten ringen die unterschiedlichen Organisationen und durch sie die EU-Mitgliedsstaaten um den sogenannten &#8220;AI Act&#8221;, d.h. das umfassende Regulierungspaket zum Thema &#8220;KI&#8221;. Solche Verhandlungen sind im Parlamentarismus zäh und langwierig, was aber kein Bug ist, sondern ein Feature: Der lange Deliberationsprozess ist auch die Chance, mehr Perspektiven einfließen zu lassen als nur die einiger Lobbyorganisationen.</p>



<p>In den letzten Monaten erreichten die Verhandlungen die Ziellinie, doch kurz vor Ende tauchten plötzlich doch wieder streitbare Punkte (wie beispielsweise die Legalisierung und Legitimation von biometrischer Massenüberwachung durch &#8220;KI&#8221;) im Text auf, so dass die Verhandlungen immer wieder herausfordernd wurden. Insbesondere die Bundesregierung wie auch Frankreich stehen aktuell einer Verabschiedung des AI Actes im Wege: Einerseits haben beide jeweils Startups (in Deutschland zum Beispiel Aleph Alpha) im Ohr, die weniger Regulierung/mehr Innovationsfreiräume fordern, andererseits gibt es auch das Argument, dass Überwachungsbefugnisse im AI Act zu groß sind. </p>



<p>Doch diese Konflikte seriös auszuhandeln, scheint den Aktivismus einiger zu überfordern: Die Stiftung Mercator, die seit einigen Monaten sehr präsent im Bereich digitaler Policy ist, hat nun diverse Organisationen und Einzelpersonen aktiviert, um in <a href="https://www.ai-act-verabschieden.de/">einem offenen Brief</a> die Bundesregierung aufzufordern den aktuellen Entwurf nun doch endlich durchzuwinken. Aber es stellen sich mir doch einige Fragen.</p>



<h2 class="wp-block-heading">Warum eigentlich?</h2>



<p>Ein offener Brief, der solche Forderungen für weitreichende Gesetzgebung auftstellt, wird ja sicher Gründe geben. Welche gibt der offene Brief?</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;Um Rechtssicherheit für Unternehmen, verbindliche, verhältnismäßige Standards für vertrauenswürdige KI zu schaffen, sollte deshalb eine Einigung noch in dieser Legislatur erfolgen.&#8221;</p>
</blockquote>



<p>Okay, Unternehmen wollen wissen, wie weit sie wo gehen dürfen. Ist aus Sicht dieser Unternehmen ja verständlich, aber warum sollte sich die Zivilgesellschaft jetzt für ein paar Startups vor den Karren spannen lassen? Für die Professor*innen ergibt das Sinn, man erhoffte sich gemeinsame Forschungs- und Förderprojekte, aber das klingt eher nach spezifischen Interessen und nicht der großen gesellschaftlichen Vision.</p>



<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>Mit dem Entwurf für den AI Act hat sich die EU als Pionier in der KI-Regulierung positioniert.</p>
</blockquote>



<p>Ahh, da haben wir wieder das beliebte Mem: Aber wir müssen doch ERSTE!!11 sein, wenn schon nicht mit Technik, dann mit Regulierung (ich schrieb <a href="https://tante.cc/2024/01/22/der-mangel-an-gestaltungswillen/">neulich dazu</a>). Aber müssen wir unbedingt jetzt unbedingt Alpha Tester*innen einer Regulierung sein, wenn &#8220;KI&#8221; denn so wichtig wird, wie der offene Brief hinbehauptet? Wäre &#8211; wenn &#8220;KI&#8221; wirklich so essentiell für alles sein wird &#8211; nicht eine wirklich gute, grundrechtskompatible, politische Regulierung nötig, die nicht auf diffusen Narrativen sondern Konkreten Einsatz- und Bedrohungsszenarien operiert? Warum die Hektik?</p>



<p>Man hört oft, dass es darum geht, das jetzt schnell zu machen, weil im Herbst überall die Rechtspopulisten und Faschisten gewählt werden, aber ist nicht gerade <em>dann</em> insbesondere die Art, wie der AI Act die Nutzung von &#8220;KI&#8221; zur Massenüberwachung und an den Grenzen erlaubt, absolut unverhandelbar? Warum sollen wir jetzt hektisch den Rechtspopulist*innen die Maschinen für ihre Visionen der Unterdrückung des Widerstandes legalisieren?</p>



<h2 class="wp-block-heading">Innovation also</h2>



<p>Das Dokument ist ein gutes Beispiel für &#8220;AI Realism&#8221;, d.h. den Glaube, dass am flächendeckenden und alles beeinflussendem Einsatz von &#8220;KI&#8221; absolut kein Weg vorbei führt. Wir können evtl. noch die Regulierungen bauen, die es europäischen Unternehmen erlaubt, auch mitzuspielen, aber einen echten politischen Gestaltungsrahmen, der aus Werten heraus argumentiert, besteht nicht.</p>



<p>Innovation ist qua Definition unkonkret: Niemand weiß, welche Innovationen die Zukunft bringen wird. Indem &#8220;KI&#8221; nun mit einem generellen Innovationsversprechen aufgeladen wird, wird ein echter Diskurs über Technikeinsatz und die Ziele, die wir als Gesellschaft damit verfolgen wollen, blockiert. Denn in allen möglichen Zukünften löst &#8220;KI&#8221; sicher irgendwo alle unsere Probleme. Ob wir in diesen Zukünften leben werden? Weiß niemand. Aber ein paar Startups werden immerhin viel Geld damit verdienen, sich an Microsoft/Google zu verkaufen.</p>



<p>Innovation ist kein politischer Wert. Innovationsversprechen verschieben aktuelle politische Diskussionen in die diffuse Zukunft und reduzieren den Raum des denk- und sagbaren auf die Auswahl von Technologien und deren, die sie entwickeln dürfen. </p>



<p>Der ganze offene Brief spricht diffus vom &#8220;Schutz der Bürger*innen&#8221;, es wird also erkannt, dass &#8220;KI&#8221; Systeme eben auch nicht zuletzt signifikantes Bedrohungspotenzial mit sich bringen: &#8220;KI&#8221; und Austeritätsbasierter Neoliberalismus sind quasi Geschwister. Wir wollen uns keine Investitionen in Care leisten, also kriegen Menschen nur noch &#8220;KI&#8221; &#8220;Fürsorge&#8221;. &#8220;Alle&#8221; nutzen autonome Waffensysteme, da wollen wir doch nicht zurückstehen? Rheinmetall kann da doch sicher auch noch was verdienen? Und das komplett haltlose Versprechen, dass &#8220;KI&#8221; uns bei der Klimakrise hilft, kann man auch immer bringen.</p>



<p>Was der Brief nie bringt ist ein politisches Argument jenseits von &#8220;Unternehmen brauchen Rechtssicherheit für Innovation&#8221;. Es geht nie um die bessere Verwirklichung der Rechte der Menschen innerhalb der EU, um qualitative Verbesserungen im Leben dieser. Es geht um die Extraktionsmaschine, die die Welt an den Rand des Ruins gebracht hat, und wie wir da auch mitmachen können. Okay, kann man ja finden, aber dann würde ich da eher Unternehmensverbände wie ECO oder Bitkom als Unterzeichner erwarten und nicht eine angebliche &#8220;Zivilgesellschaft&#8221;.</p>



<h2 class="wp-block-heading">Besser als Nichts? </h2>



<p>Netzpolitik.org hat am Freitag über die diversen <a href="https://netzpolitik.org/2024/grundrechte-in-gefahr-die-sieben-quaelendsten-fragen-zur-ki-verordnung/">Grundrechtsprobleme des AI Actes geschrieben</a>. Biometrische Überwachung, &#8220;Migrationskontrolle&#8221;, Freibriefe für die &#8220;Nationale Sicherheit&#8221;, das liest sich nun alles nicht wie ein zukunftsgerichtetes Dokument auf Basis eines freiheitlich-solidarischen Europas sondern eher wie Dinge, die man eher CDU-Innenministerien zuschreiben würde. </p>



<p>Und auch die weitgehende Carte Blanche, die man sogenannten &#8220;Foundation Models&#8221; ausstellt, ist eher sportlich. Foundation sind diese riesigen, unüberprüfbaren, intransparenten Modelle wie GPT4 von OpenAI oder die weitgehend unmoderierte Famile der Luminous Modelle von Aleph Alpha, die man auf nahezu beliebige Szenarien anwenden kann (also ohne Garantien, was genau sie dann jeweils ausgeben, aber rein formal, kann man sie auf alles anwenden). In einer Demokratie müsste man eigentlich skeptisch werden, wenn Unternehmen mit Gewinnerzielungsabsicht komplett opake Systeme an den Markt bringen wollen, die intransparente Entscheidungen im Kleinen und Großen treffen. Wie genau stellt man denn dann sicher, dass Fairness, Diskriminierungsfreiheit und andere Grundrechte geachtet werden?</p>



<p>Der offene Brief wischt das mit  &#8220;unterschiedlichen Perspektiven auf die Verbesserung bei der Ausgestaltung&#8221; weg. Das überrascht wenig, wenn man gut situierte Akedemiker*innen und Menschen mit direkten Verbindungen zur Industrie befragt: Diese Schichten haben viel zu gewinnen (nicht zuletzt Förderungen) und wenig zu verlieren, da sie nicht zu den Bevölkerungsgruppen gehören, gegen die solche Systeme zuerst eingesetzt werden (schon jetzt kommen ja immer wieder Vorschläge auf, Sozialleistungen durch &#8220;KI&#8221; verteilen/ablehnen zu lassen, das Thema Migration wurde ja auch schon von Netzpolitik angesprochen). Unter den Prämissen kann man mit so Grundrechtsproblemen natürlich ganz locker umgehen.</p>



<h2 class="wp-block-heading">Unabhängige Zivilgesellschaft</h2>



<p>Eine unabhängige Zivilgesellschaft darf sich natürlich auch in offenen Briefen und durch diverse andere  Mittel organisieren und Gehör verschaffen. Soll und muss sie sogar. </p>



<p>Doch wie weit ist es mit der Unabhängigkeit her, wenn ein der großer Player für die Finanzierung von Projekten im Bereich von Wissenschaft und Zivilgesellschaft das eigene Netzwerk zur Zeichnung auffordert? Wie frei sind NGOs und Expert*innen, die gerade schon Geld von Mercator/Bertelsmann bekommen bzw. gerade an Anträge arbeiten? </p>



<p>Ich habe mal angefangen unter <a href="https://pad.riseup.net/p/SIr0IqcKeFluyVlTJNg6-keep">https://pad.riseup.net/p/SIr0IqcKeFluyVlTJNg6-keep</a> zu sammeln, welche der Unterzeichnenden eine direkte Beziehung zur Mercator und Bertelsmann Stiftung haben (gerne beteiligen), aber auch ohne direkte Beziehung gibt es natürlich aufgrund der Förderlandschaft in Deutschland oft eine indirekte Beziehung: Wer will es sich schon mit großen Geldgebern verscherzen?</p>



<p>Die Situation wirft ein Spotlight auf die Abhängigkeit des gesellschaftlichen Engagements von wenigen privaten Akteuren, die keinerlei demokratischer oder öffentlicher Kontrolle unterliegen. Am Ende können nur die Beteiligten sagen, warum genau sie sich nun für wirtschaftliche Ziele in die Bresche werfen.  </p>



<h2 class="wp-block-heading">Fazit </h2>



<p>Der offene Brief &#8220;der Zivilgesellschaft&#8221; vertritt sehr einseitig Interessen der Wirtschaft und einiger Menschen im Politikbetrieb, die auch mal &#8220;ERSTER!&#8221; sein wollen. Und das ohne echten Bezug auf eine politische oder gesellschaftliche Vision. &#8220;KI&#8221; ist alternativlos und wir können evtl. ein bisschen was ein bisschen weniger schlecht machen &#8211; so lange es nicht der heiligen <em>Innovation</em> im Wege steht.</p>



<p>Aber warum genau wir nun kopflos eine sehr ausbaufähige Regulierung verabschieden müssen, erschließt  sich mir nicht. Gerade wenn die Grundrechtsprobleme keineswegs trivial sind.</p>



<p>Ich bin kein Fan des AI Act. Der Einfluss der Lobbyisten ist überall lesbar, die Mechanik selbst finde ich nicht sehr überzeugend und diverse andere Aspekte lesen sich vielleicht auf den ersten Blick nett, aber werden in der Umsetzung wahrscheinlich eher ein Schlag ins Wasser. Aber trotzdem kann es natürlich eine sinnvolle Regulierung werden, die bestimmte Aspekte dieser Statistiksysteme noch mal expliziter fasst und in unseren bestehenden Rechts- und Werterahmen einzuordnen. Aber wir haben ja genau diesen Rechtsrahmen, es ist ja nicht so, als gäbe es keine Regulierung, die IT Systeme betrifft.</p>



<p>Warum genau unbedingt jetzt <em>irgendwas, egal was</em> verabschiedet werden soll, können wohl nur die Unterzeichnenden beantworten. Ebenso wie die Frage, warum sie so wenig Relevanz in der Aufweichung von Grundrechten sehen.</p>



<p>Ich hätte lieber eine auf politischen Werten und Zielen fußende, durchdachte Regulierung. Und wenn man das gerade nicht hinbringt, muss man halt noch weiter verhandeln. Mit magischer &#8220;Innovation&#8221; zu winken, ist mir allerdings dann doch zu wenig.</p>
