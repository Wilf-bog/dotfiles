
<p>I just got an email from a store I bought something at about 4 months ago. It happens, they have my mail, somewhere in their fine print they said that they were gonna send me product recommendations or I clicked a thing because it looked like the box you have to click to get the thing.</p>



<p>I&#8217;m not even mad about it, it does sometimes make sense. The store where we order cat food sends out coupons and I can save a bit on chewy treats for our libertarian overlords here, for example. The company that just send me the email about new products? The sell automatic standing desks. How many of those do I buy every quarter? About zero now that I have one &#8211; I have only so many rooms to fill and so many bodies to place at tables.</p>



<p>Now of course they could think that I have this huge company with staff who all need standing desks (get one, they&#8217;re great, I wished the office I work in had them) but how big are the chances really?</p>



<p>People know the scary stories of &#8220;surveillance capitalism&#8221; and how Facebook and other platforms knows us better than we do. How they can predict our needs with sophisticated algorithms, shape our world and behavior. Because we are just these simplistic animals that if they see something they need it and buy it.</p>



<p>The standing desk company isn&#8217;t the most sophisticated in the world when it comes to data analytics and algorithms I guess. They probably just use some ready-made ecommerce solution that sends out emails. But there are more sophisticated players in that space, with limitless resources and the smartest programmers and statisticians on staff. There is Amazon.</p>



<p>You might have heard for example that Amazon ships products already to fulfillment centers near hotspots before they have been ordered to ship faster and that they then use their algorithmically sorted page to push the things they already transported to your neightborhood to you. That they track and analyze every click you make to try to get you to buy things, especially things you did look at. </p>



<p>These things then follow you around and keep being presented to you. <em>Buy this, you did check it out, right? You want this!</em> </p>



<p>I do buy stuff on Amazon at times (I try to avoid it but sometimes it&#8217;s hard) so I have products following me around. I remember a few years ago I was looking to buy a TV, I browsed some and all my recommendations were TVs and then I bought the one I wanted. </p>



<p>But the recommendations didn&#8217;t go away. Amazon kept showing me more TVs. Now I needed exactly one TV. I don&#8217;t need more of those things in this home. But these things kept following me around in <em>spite of me buying a TV an Amazon based on my comparison</em>.</p>



<p>Digital systems have a tendency to flatten everything. Because flat is easy to implement. We see that more than anywhere with modern &#8220;AI&#8221; systems but other systems also have the same tendency. What do I mean by that? Flatten?</p>



<p>Amazon for example doesn&#8217;t care <em>why</em> you look at an object. Maybe you want to buy something, maybe you just wanted to look up the technical specs or someone sent you a link to a funny review. All the same to Amazon. The complexity of the world flatted to a little &#8220;but you looked at this&#8221; flag. Same for buying stuff. Amazon builds your profile to suggest things that might be relevant to you but then just adds everything you buy (you can modify it but it&#8217;s an annoying process) to your profile. Even the thing you bought for your niece as a birthday gift. Or your dad&#8217;s last Christmas present. All these things are being flattened. Stripped of context and nuance and messiness. Perfectly flat and neat. <em>A model build not to understand you but to enable an algorithm to work efficiently</em>. You are just a data provider.</p>



<p>I think this shows us another crack in tech&#8217;s narrative of being so uber-powerful and data being the perfect source of truth and future forecasting (another &#8220;AI&#8221; related narrative here, &#8220;AI&#8221; is really just the continuation of the tech development of the last 10-15 years, just a bit more wasteful). Because while the algorithms might be smart and efficient and might scale. Might build profiles of people in nanoseconds while comparing products to millions of people in milliseconds all that is built on a flattend world view.</p>



<p>I don&#8217;t have a grand point to make here. Just a random observation while deleting mails from my inbox: A lot of discourse might be lead by people thinking themselves to be the smartest people in the room with access to the only real magic there is, data. But when we look at what all that data analytics does it quickly just looks very mediocre. Like something that goes through some motion without understanding context and the world. Like something mimicking something real but without any understanding for it and therefore failing. Kinda like modern &#8220;AI&#8221; systems. </p>
