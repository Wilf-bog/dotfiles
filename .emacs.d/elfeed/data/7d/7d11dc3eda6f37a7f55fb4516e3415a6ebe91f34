
<p>The conversation about the &#8220;dangers of AI&#8221; is full of weird little tidbits that show only marginal connection to the real world. Is stochastic parrots becoming Skynet really a thing? Will some future &#8220;AI&#8221; lock us in a <a href="https://en.wikipedia.org/wiki/Roko%27s_basilisk">torture VR environment</a> for not helping it emerge fast enough? You know probably a dozen of them or more.</p>



<p>The historian David Brock coined the term “wishful worries,” which he described as “problems that it would be nice to have”. We see that a lot in tech discourse: Instead of focusing on real, material effects of tech, we talk about SciFi stories that are way more dramatic and theoretically more dangerous. Why talk about &#8220;AI&#8221; destroying creative jobs when we could talk about &#8220;KILLER AI THAT WILL MAKE US ALL A PAPERCLIP!!!!&#8221;. The first one is uncomfortable and we might know people actually affected whereas the second one is just something to &#8220;philosophize&#8221; about over drinks. Which admittedly is a lot more pleasant probably &#8211; unless you are one of the people actually effected by the tech of course. The mechanism shares some structure with Bruce Schneier&#8217;s idea of <a href="https://en.wikipedia.org/wiki/Security_theater">Security Theater</a> (and his related idea of Movie Plot Threats): Our security apparatuses are built around threat models that would work in a Bond Movie but not in the real world because in the real world often more simple and less flashy things would do the trick.</p>



<p>Currently when talking about very big large language models even people who want to be taken seriously talk a lot about bio or chemical weapons: Will &#8220;AI&#8221; systems make creating bio weapons too easy? OpenAI actually did a <a href="https://www.theverge.com/2024/2/1/24058095/open-ai-bioweapon-study-preparedness-team">study recently on this</a> and found: Only a bit. Great.</p>



<p>But is that a real danger? A real threat we need to deal with? Will ChatGPT give terrorists new weapons to attack us that nobody even knows about? </p>



<p>I think this is the definition of a wishful worry, a thing to talk about while getting increasingly drunk or baked. A thing Elon Musk would think to be <em>deep</em>. </p>



<p>If you were a terrorist and were looking for chemical or biological weapons, would your first approach be ChatGPT? Chemical and bio weapons are special because they feel different from purely conventional bombs: They feel even more invasive, more threatening, so that fits in well with terrorism.</p>



<p>So ChatGPT finds you a new chemical or bio weapon. Now you need to produce the stuff. There&#8217;s no best practice for it yet, no process pipeline, no experience with production risks. Maybe you need certain very specific chemicals or facilities to produce your new very dirty bomb. Maybe get a cat with white fur to stroke while you&#8217;re waiting. Is that worth it?</p>



<p>If you search for a bit on &#8220;the dark web&#8221; (or just browse a bit through security warnings in beginners&#8217; chemistry books) you will find very dangerous, effective weapons to create in your bath tub with stuff from the drug store and the supermarket. The process to create those substances is well defined, you need no special, suspicious equipment or materials. Why would you risk something ChatGPT made up that might not even work or be stable enough to use when it&#8217;s so easy to build harmful substances already?</p>



<p>To be more efficient? If your goal is terror do you really care if you hurt 100 or 120 people? The publicity impact is the same. You don&#8217;t need efficiency, you need to show you can act where you want and make people afraid. You don&#8217;t need Bond supervillain type of crap.</p>



<p> It&#8217;s a distraction. A BIG and SCARY thing to debate when the actual impacts are tangible <em>right now</em> but would require structural interventions to curb them. Especially when most negative impacts of &#8220;AI&#8221; are <a href="https://tante.cc/2023/11/10/thoughts-on-generative-ai-art/">direct consequences of Capitalism</a>. But we can&#8217;t think about whether growth-based capitalism is eating the world (also through AI). We&#8217;d rather have a drink, cosy up in our rooms and philosophize about magical bio weapons made by AI. It&#8217;s so much nicer and doesn&#8217;t demand anything from us. Maybe some regulation that would never trigger. (And even Europe&#8217;s fancy new AI act doesn&#8217;t really limit state level actors from using AI to build weapons if they want to.)</p>



<p>When talking AI risks we need to stop giving any more air to these dumb ideas that take up so much space in the conversation. Talk about how real people right now are affected and leave your bio weapons, Skynet and whatever else Sam Altman and Elon Musk wanna think about in the gutter where it belongs.</p>
